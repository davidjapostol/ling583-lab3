{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "planned-olive",
   "metadata": {},
   "source": [
    "# LAB 3: Automated Terminology Extraction\n",
    "\n",
    "Extract technical terms from ACL Anthology\n",
    "\n",
    "Objectives:\n",
    "* part of speech tagging with spacy\n",
    "* extract phrases that match a part of speech pattern\n",
    "* scale processing pipeline with dask\n",
    "* compute c-values\n",
    "\n",
    "## Part I: Test c-value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "checked-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adaptive-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/acl.parquet', storage_options={'anon':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "taken-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(500, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-zambia",
   "metadata": {},
   "source": [
    "### Set up spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alike-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gentle-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', exclude=['parser', 'ner', 'lemmatizer', 'attribute_ruler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessory-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "similar-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Term', [[{'TAG': {'IN': ['JJ', 'NN']}},\n",
    "                      {'TAG': {'IN': ['JJ', 'NN', 'IN', 'HYPH']}, 'OP': '*'},\n",
    "                      {'TAG': 'NN'}]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-irish",
   "metadata": {},
   "source": [
    "### Extract candidate terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sized-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(text):\n",
    "    doc = nlp(text)\n",
    "    spans = matcher(doc, as_spans=True)\n",
    "    return [tuple(tok.norm_ for tok in span) for span in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rental-brake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84098a006882426cbaadcff734c676bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidates = list(concat(df['text'].progress_apply(get_candidates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "buried-differential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('effective', 'approach'),\n",
       " ('approach', 'for', 'resume'),\n",
       " ('effective', 'approach', 'for', 'resume'),\n",
       " ('resume', 'information'),\n",
       " ('approach', 'for', 'resume', 'information'),\n",
       " ('effective', 'approach', 'for', 'resume', 'information'),\n",
       " ('information', 'extraction'),\n",
       " ('resume', 'information', 'extraction'),\n",
       " ('approach', 'for', 'resume', 'information', 'extraction'),\n",
       " ('effective', 'approach', 'for', 'resume', 'information', 'extraction')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-italic",
   "metadata": {},
   "source": [
    "### Compute c-values\n",
    "\n",
    "$$\\mbox{C-value}(a)=\\begin{cases}\\log_2|a|\\cdot f(a) & \\mbox{if } a \\mbox{ is not nested}\\\\\\log_2|a|\\left(f(a)-\\frac{1}{P(T_a)}\\sum_{b\\in T_a}f(b)\\right) & \\mbox{otherwise}\\\\\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "molecular-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "radical-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = defaultdict(Counter)\n",
    "for c in candidates:\n",
    "    freqs[len(c)][c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "norwegian-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fifteen-novel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(4, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tight-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subterms(term):\n",
    "    k = len(term)\n",
    "    for m in range(k-1, 1, -1):\n",
    "        yield from ngrams(term, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "complimentary-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "defensive-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_value(F, theta):\n",
    "    \n",
    "    termhood = Counter()\n",
    "    longer = defaultdict(list)\n",
    "    \n",
    "    for k in sorted(F, reverse=True):\n",
    "        for term in F[k]:\n",
    "            if term in longer:\n",
    "                discount = sum(longer[term]) / len(longer[term])\n",
    "            else:\n",
    "                discount = 0\n",
    "            c = log2(k) * (F[k][term] - discount)\n",
    "            if c > theta:\n",
    "                termhood[term] = c\n",
    "                for subterm in get_subterms(term):\n",
    "                    if subterm in F[len(subterm)]:\n",
    "                        longer[subterm].append(F[k][term])\n",
    "    return termhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "referenced-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = c_value(freqs, theta=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "coordinated-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  446.00  446 language model\n",
      "  420.27  213 part - of - speech\n",
      "  317.00  458 natural language\n",
      "  310.00  310 training set\n",
      "  307.48  194 sentence - level\n",
      "  298.00  381 machine translation\n",
      "  271.00  271 other hand\n",
      "  265.00  265 test set\n",
      "  261.00  261 previous work\n",
      "  251.00  306 neural network\n",
      "  242.50  153 word - level\n",
      "  238.00  238 word alignment\n",
      "  229.87   99 end - to - end\n",
      "  223.48  141 natural language processing\n",
      "  220.00  220 future work\n",
      "  209.22  132 n - gram\n",
      "  209.22  132 large - scale\n",
      "  198.00  270 co -\n",
      "  194.95  123 f - measure\n",
      "  193.37  122 f - score\n"
     ]
    }
   ],
   "source": [
    "for t, c in terms.most_common(20):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "trying-portuguese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84.00   84 target domain\n",
      "   83.00   83 sentence level\n",
      "   82.72   32 part - of - speech tagging\n",
      "   80.83   51 part of speech\n",
      "   80.00   80 first step\n",
      "   80.00   80 head word\n",
      "   80.00   80 sentence pair\n",
      "   79.00   79 time step\n",
      "   78.00   78 baseline system\n",
      "   78.00   78 - word\n",
      "   77.66   49 t - test\n",
      "   77.66   49 character - level\n",
      "   77.00   77 related work\n",
      "   77.00   77 sentence compression\n",
      "   76.00   76 mutual information\n",
      "   76.00   76 re -\n",
      "   76.00   76 small number\n",
      "   76.00   76 deep learning\n",
      "   76.00   76 recent work\n",
      "   76.00   76 text classification\n"
     ]
    }
   ],
   "source": [
    "for t, c in tail(20, terms.most_common()):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-ethnic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
