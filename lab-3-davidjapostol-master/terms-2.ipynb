{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becoming-alias",
   "metadata": {},
   "source": [
    "# LAB 3: Automated Terminology Extraction\n",
    "\n",
    "Extract technical terms from ACL Anthology\n",
    "\n",
    "Objectives:\n",
    "* part of speech tagging with spacy\n",
    "* extract phrases that match a part of speech pattern\n",
    "* scale processing pipeline with dask\n",
    "* compute c-values\n",
    "\n",
    "## Part I: Test c-value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "complicated-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "brown-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42605</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42605' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:42605\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ambient-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/acl.parquet', storage_options={'anon':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "resistant-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "appointed-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.from_pandas(df, npartitions=100)\n",
    "texts = df['text'].to_bag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-candy",
   "metadata": {},
   "source": [
    "### Set up spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "legal-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abstract-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', exclude=['parser', 'ner', 'lemmatizer', 'attribute_ruler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "involved-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "greek-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Term', [[{'TAG': {'IN': ['JJ', 'NN']}},\n",
    "                      {'TAG': {'IN': ['JJ', 'NN', 'IN', 'HYPH']}, 'OP': '*'},\n",
    "                      {'TAG': 'NN'}]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-detective",
   "metadata": {},
   "source": [
    "### Extract candidate terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "designed-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(text):\n",
    "    doc = nlp(text)\n",
    "    spans = matcher(doc, as_spans=True)\n",
    "    return [tuple(tok.norm_ for tok in span) for span in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "attempted-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = texts.map(get_candidates) \\\n",
    "             .flatten() \\\n",
    "             .frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "velvet-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 1.56 s, total: 12.3 s\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "candidates = graph.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hundred-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('polynomial', 'time'), 234),\n",
       " (('recognition', 'phase'), 17),\n",
       " (('input', 'string'), 379),\n",
       " (('spurious', 'ambiguity'), 148),\n",
       " (('function', 'application'), 40),\n",
       " (('relative', 'ordering'), 29),\n",
       " (('considerable', 'interest'), 40),\n",
       " (('large', 'number'), 1357),\n",
       " (('same', 'function'), 26),\n",
       " (('function', 'argument'), 5)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "polar-flesh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920136"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-stanley",
   "metadata": {},
   "source": [
    "### Compute c-values\n",
    "\n",
    "$$\\mbox{C-value}(a)=\\begin{cases}\\log_2|a|\\cdot f(a) & \\mbox{if } a \\mbox{ is not nested}\\\\\\log_2|a|\\left(f(a)-\\frac{1}{P(T_a)}\\sum_{b\\in T_a}f(b)\\right) & \\mbox{otherwise}\\\\\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "contemporary-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "streaming-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = defaultdict(Counter)\n",
    "for c, f in candidates:\n",
    "    freqs[len(c)][c] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "leading-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "advisory-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subterms(term):\n",
    "    k = len(term)\n",
    "    for m in range(k-1, 1, -1):\n",
    "        yield from ngrams(term, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "functional-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "special-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_value(F, theta):\n",
    "    \n",
    "    termhood = Counter()\n",
    "    longer = defaultdict(list)\n",
    "    \n",
    "    for k in sorted(F, reverse=True):\n",
    "        for term in F[k]:\n",
    "            if term in longer:\n",
    "                discount = sum(longer[term]) / len(longer[term])\n",
    "            else:\n",
    "                discount = 0\n",
    "            c = log2(k) * (F[k][term] - discount)\n",
    "            if c > theta:\n",
    "                termhood[term] = c\n",
    "                for subterm in get_subterms(term):\n",
    "                    if subterm in F[len(subterm)]:\n",
    "                        longer[subterm].append(F[k][term])\n",
    "    return termhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "perceived-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = c_value(freqs, theta=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dying-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5236.00 5682 language model\n",
      " 4461.67 5060 machine translation\n",
      " 4451.14 2330 part - of - speech\n",
      " 4410.50 5388 natural language\n",
      " 3583.00 3583 training set\n",
      " 3379.00 3920 neural network\n",
      " 3346.00 3346 previous work\n",
      " 3171.75 1366 end - to - end\n",
      " 3012.00 3012 other hand\n",
      " 3003.00 3003 test set\n",
      " 2923.00 2923 future work\n",
      " 2589.83 1634 natural language processing\n",
      " 2370.00 2370 target language\n",
      " 2317.22 1462 sentence - level\n",
      " 2301.37 1452 large - scale\n",
      " 2209.44 1394 word - level\n",
      " 2174.00 2174 parse tree\n",
      " 2144.45 1353 n - gram\n",
      " 2059.00 2059 training corpus\n",
      " 2019.24 1274 f - score\n"
     ]
    }
   ],
   "source": [
    "for t, c in terms.most_common(20):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "phantom-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  516.70  326 sub - word\n",
      "  515.11  325 chinese word segmentation\n",
      "  515.00  515 lexical information\n",
      "  515.00  515 morphological analysis\n",
      "  515.00  515 input sequence\n",
      "  514.00  514 classification problem\n",
      "  513.00  513 local context\n",
      "  512.00  512 time complexity\n",
      "  511.00  511 text generation\n",
      "  511.00  511 probabilistic model\n",
      "  511.00  511 tree kernel\n",
      "  510.00  510 phrase pair\n",
      "  509.00  509 distributional similarity\n",
      "  508.77  321 natural language generation\n",
      "  508.77  321 f1 - score\n",
      "  508.77  321 hyper - parameter\n",
      "  507.19  320 set of candidate\n",
      "  507.00  507 standard deviation\n",
      "  504.00  504 beam size\n",
      "  503.00  503 dependency relation\n"
     ]
    }
   ],
   "source": [
    "for t, c in tail(20, terms.most_common()):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "satisfied-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('terms.txt', 'w') as f:\n",
    "    for term in terms:\n",
    "        print(' '.join(term), file = f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
